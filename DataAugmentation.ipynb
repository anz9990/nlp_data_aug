{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/revs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/revs/valid'),\n",
       " PosixPath('data/revs/models'),\n",
       " PosixPath('data/revs/train')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  is_valid\n",
       "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "1  positive  This is a extremely well-made film. The acting...     False\n",
       "2  negative  Every once in a long while a movie will come a...     False\n",
       "3  positive  Name just says it all. I watched this movie wi...     False\n",
       "4  negative  This movie succeeds at being one of the most u...     False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/\"../imdb_sample/texts.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cast does an excellent job with the script . \\n \\n  xxmaj but it is hard to watch , because there is no good end to a situation like the one presented . xxmaj it is now xxunk to blame the xxmaj british for setting xxmaj hindus and xxmaj muslims against each other , and then xxunk xxunk them into two countries . xxmaj there is some merit in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>love ? xxmaj sounds like after xxmaj alex moved into the building which xxmaj kiki was living , then two girls are fall in love . xxmaj it does n't make sense at all . xxmaj how a girl would fall in love with another girl instead of a man . xxmaj too much xxunk , you need to image and connect those stories by your mind . xxmaj secondly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>either as his wife , but xxmaj xxunk xxmaj xxunk , xxmaj michael xxmaj xxunk , and xxmaj xxunk xxmaj wilson are fine in support . xxmaj it 's also worth it to see xxunk like xxmaj xxunk \" xxmaj xxunk \" xxmaj smith ( doing an xxunk topless shot ) , xxmaj xxunk xxmaj xxunk ( of xxmaj tobe xxmaj xxunk ' \" xxmaj xxunk xxmaj alive \" and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>plot involves xxmaj satan 's efforts to xxunk xxmaj santa xxmaj claus ' xxmaj christmas xxmaj eve xxunk with the xxmaj earth 's children ; there is , however , plenty more xxunk along the way : to begin with , our xxunk , white - xxunk and xxunk merry man - in - red lives in a xxunk palace who , apart from xxunk toy - xxunk kids from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>thin line between xxunk and reality and ends up confusing his role with his own life and eventually kills his xxunk xxmaj xxunk has no memory of the xxunk xxunk . \\n \\n  xxmaj colman seems xxunk in this role . xxmaj winters is very impressive as the young woman xxunk to get away from her xxunk life . xxmaj also in the cast : xxmaj edmond o'brien ,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = (TextList.from_df(df,path,cols=\"text\")\n",
    "                   .split_by_rand_pct()\n",
    "                   .label_for_lm()\n",
    "                   .databunch())\n",
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import nltk \n",
    "from nltk.corpus import wordnet \n",
    "import en_core_web_lg\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = nlp(\"he\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_pronouns = [\"I\", \"you\", \"he\", \"she\", \"it\", \"they\"]\n",
    "object_pronouns = [\"me\", \"you\", \"him\", \"her\", \"it\"]\n",
    "possessive_pronouns = [\"my\", \"mine\", \"your\", \"yours\", \"his\", \"her\", \"hers\", \"its\"]\n",
    "interrogative_pronouns = [\"who\", \"whom\", \"whose\", \"what\", \"which\"]\n",
    "indefinite_pronouns = [\"another\", \"each\", \"everything\", \"nobody\", \"either\", \"someone\"]\n",
    "relative_pronouns = [\"who\", \"whom\", \"whose\", \"that\", \"which\"]\n",
    "reflexive_pronouns = [\"myself\", \"yourself\", \"himself\", \"herself\", \"itself\"]\n",
    "demonstrative_pronouns = [\"this\", \"that\"]\n",
    "pronouns = [subject_pronouns,object_pronouns,possessive_pronouns,interrogative_pronouns,\n",
    "           indefinite_pronouns,relative_pronouns,demonstrative_pronouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synalter_noun_verb_adjective_pronoun(cand_word,POS):\n",
    "    thresh = -1\n",
    "    scores = []\n",
    "    if POS == \"prn\": \n",
    "        for p_list in pronouns:\n",
    "            if cand_word in p_list: \n",
    "                synonyms = set(p_list)\n",
    "                synonyms = list(synonyms.remove(cand_word))\n",
    "    synonyms = wordnet.synsets(cand_word)\n",
    "    for w2 in synonyms:\n",
    "        try:\n",
    "            w1 = wordnet.synset(cand_word+'.'+POS+'.01') \n",
    "        #w2 = wordnet.synset(word+'.'+POS+'.01') # n denotes noun \n",
    "            if (w1.wup_similarity(w2)>thresh):\n",
    "                scores.append(w1.wup_similarity(w2))\n",
    "            return synonyms[np.argmax(scores)].name().split('.')[0].replace('_',' ')\n",
    "        except:\n",
    "            if not scores:\n",
    "                for synset in synonyms:\n",
    "                    word=synset.name().split('.')[0].replace('_',' ')\n",
    "                    #print(word)\n",
    "                    token = nlp(word)\n",
    "                    token_main = nlp(cand_word)\n",
    "                    if token.vector_norm and token_main.vector_norm and float(token.similarity(token_main)) > thresh:\n",
    "                        scores.append(float(token.similarity(token_main)))\n",
    "            return synonyms[np.argmax(scores)].name().split('.')[0].replace('_',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON', 'ADJ', 'NOUN', 'VERB']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('he bright car running')\n",
    "[tok.pos_ for tok in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_words(word_str,pos,output_text):\n",
    "    change_word=synalter_Noun_Verb(word_str,pos)\n",
    "    if change_word:\n",
    "        search_word = re.search(r'\\b('+word_str+r')\\b', output_text)\n",
    "        Loc = search_word.start()\n",
    "        output_text = output_text[:int(Loc)] + change_word + output_text[int(Loc) + len(word_str):] \n",
    "        \n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_into_files(df,path):\n",
    "    for i in range(len(df)):\n",
    "        review = str(df.iloc[i][\"text\"])\n",
    "        if not df.iloc[i][\"is_valid\"]:\n",
    "            if df.iloc[i][\"label\"] == \"positive\": \n",
    "                with open(str(path)+f\"/train/pos/{i}.txt\",\"w\") as f: f.write(review)\n",
    "            else: \n",
    "                with open(str(path)+f\"/train/neg/{i}.txt\",\"w\") as f: f.write(review)\n",
    "        else:\n",
    "            if df.iloc[i][\"label\"] == \"positive\": \n",
    "                with open(str(path)+f\"/valid/pos/{i}.txt\",\"w\") as f: f.write(review)\n",
    "            else: \n",
    "                with open(str(path)+f\"/valid/neg/{i}.txt\",\"w\") as f: f.write(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1162"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('data/revs/train/**/*.txt',recursive=True)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f for f in files if '_aug.txt' not in f] #skip already augmented files\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class text_augmenter(object):\n",
    "#    def __init__(self):\n",
    "    \n",
    "    def __call__(self, fn,i): \n",
    "        #print(f'augmenting file {fn}')\n",
    "        output_text = open(fn,'r').read()\n",
    "        #print(\"Sentence: \"+text)\n",
    "        counts = Counter(output_text.split())\n",
    "        noun = []\n",
    "        verb = []\n",
    "        doc = nlp(' '.join(w for w in [key for key,value in counts.items() if value ==1]))\n",
    "        noun = [tok.text for tok in doc if tok.pos_ == 'NOUN']\n",
    "        verb = [tok.text for tok in doc if tok.pos_ == 'VERB']\n",
    "        adj = [tok.text for tok in doc if tok.pos_ == 'ADJ']\n",
    "        pro = [tok.text for tok in doc if tok.pos_ == 'PRON']\n",
    "        cand_words = noun+verb+adj+pro\n",
    "        len_all = len(verb+noun+adj+pro)\n",
    "        random.seed(4)\n",
    "        temp = random.sample(range(len_all), random.randint(0,int(len_all*0.7)))\n",
    "        #print([cand_words[i] for i in temp])\n",
    "        for i in temp:\n",
    "            word_str = cand_words[i]\n",
    "            if i<len(verb):output_text = change_words(word_str,'v',output_text)\n",
    "            elif i<len(noun): output_text = change_words(word_str,'n',output_text)\n",
    "            elif i<len(adj):output_text=change_words(word_str,'a',output_text)\n",
    "            else:output_text=change_words(word_str,'prn',output_text)\n",
    "        new_fn = fn.replace('.txt','_aug.txt')\n",
    "        with open(new_fn,'w') as f:\n",
    "            f.write(output_text)\n",
    "        #print(f'saving augmented file to {new_fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='800' class='' max='800', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [800/800 01:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#text_augmenter()(files[0])\n",
    "parallel(text_augmenter(),files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_redact(txt_p, txt_id, chance=0.3, noise='xxunk', seed=42):\n",
    "    random.seed(seed)\n",
    "#     pick_some = False\n",
    "#     picks = 1 if pick_some else None\n",
    "    with open(txt_p, 'r') as txt_f:\n",
    "        txt = txt_f.read()\n",
    "        chosen_idx_set_list = []\n",
    "        tkns = txt.split()\n",
    "        tkn_cnt = len(tkns)\n",
    "        tkn_idx_set = set(range(tkn_cnt))\n",
    "        sample_cnt = math.ceil(tkn_cnt * chance)\n",
    "#         picked = 0\n",
    "        while sample_cnt <= tkn_cnt:\n",
    "            chosen_idx_set = set(random.sample(sorted(tkn_idx_set), k=sample_cnt))\n",
    "            chosen_idx_set_list += [chosen_idx_set]\n",
    "            tkn_idx_set -= chosen_idx_set\n",
    "            tkn_cnt = len(tkn_idx_set)\n",
    "#             picked += 1\n",
    "#             if pick_some and picked == picks:\n",
    "#                 break\n",
    "        for ver, idx_set in enumerate(chosen_idx_set_list):\n",
    "            redacted_tkns = tkns.copy()\n",
    "            redacted_txt_p = txt_p.parent / f'{txt_p.stem}_v{ver}-redacted{txt_p.suffix}'\n",
    "            with open(redacted_txt_p, 'w') as redacted_txt_f:\n",
    "                for chosen_idx in idx_set:\n",
    "                    redacted_tkns[chosen_idx] = noise\n",
    "                redacted_txt_f.write(' '.join(redacted_tkns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='0', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100% [0/0]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/projects/fastai/lib/python3.6/site-packages/fastprogress/fastprogress.py:96: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    }
   ],
   "source": [
    "data_imdb_p = Path('data/revs')\n",
    "orig_trn_txts = list(data_imdb_p.glob(f'./train/*/*[0-9].txt'))\n",
    "parallel(double_redact, orig_trn_txts, max_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out the Augmentation on a Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             #label them all with their folders\n",
    "             .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.299670</td>\n",
       "      <td>0.192940</td>\n",
       "      <td>0.925820</td>\n",
       "      <td>05:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.224495</td>\n",
       "      <td>0.165303</td>\n",
       "      <td>0.937353</td>\n",
       "      <td>06:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.245834</td>\n",
       "      <td>0.164227</td>\n",
       "      <td>0.938295</td>\n",
       "      <td>08:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.219863</td>\n",
       "      <td>0.162315</td>\n",
       "      <td>0.940054</td>\n",
       "      <td>11:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.198715</td>\n",
       "      <td>0.159760</td>\n",
       "      <td>0.940995</td>\n",
       "      <td>10:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas-aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
