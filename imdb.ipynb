{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9LbB0krq6z2"
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jMnqAd1HJ1Br"
   },
   "source": [
    "An example as baseline: [ULMFit](https://nbviewer.jupyter.org/github/fastai/fastai/blob/master/examples/ULMFit.ipynb) tutorial.\n",
    "\n",
    "> Fine-tuning a forward and backward langauge model to get to 95.4% accuracy on the IMDB movie reviews dataset. This tutorial is done with fastai v1.0.53.\n",
    "\n",
    "> The example was run on a Titan RTX (24 GB of RAM) so you will probably need to adjust the batch size accordinly. If you divide it by 2, don't forget to divide the learning rate by 2 as well in the following cells. You can also reduce a little bit the bptt to gain a bit of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QF718toQqs83"
   },
   "outputs": [],
   "source": [
    "# Ensure GPU spec; T4 is for colab and one can change it for another env.\n",
    "gpu_list = !nvidia-smi -L\n",
    "if gpu_list[0].startswith('NVIDIA-SMI has failed'):\n",
    "  print('Runtime type should be GPU.')\n",
    "elif not gpu_list[0].startswith('GPU 0: Tesla T4'):\n",
    "  display(gpu_list)\n",
    "  print('Please reset all runtimes. We need a Tesla T4 to reproduce the experiments!')\n",
    "else:\n",
    "  display(gpu_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0OcNDqMgrCca"
   },
   "source": [
    "## Dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jrjoIzboW09N"
   },
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2rwtTuykrEWy"
   },
   "outputs": [],
   "source": [
    "# Ensure no surprises from conflict packages.\n",
    "!pip check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bymTjo9wrz5f"
   },
   "outputs": [],
   "source": [
    "!pip install -qU fastai==1.0.55 jupyter-console==5.2.0 coveralls coverage datascience albumentations\n",
    "!pip check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7z1_46NArGi_"
   },
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMm8qgQqD2eC"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from google.colab import drive\n",
    "\n",
    "from fastai import basic_train, basic_data, core\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastprogress import fastprogress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DTVchfsRnLgI"
   },
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnxWkqafNxvA"
   },
   "outputs": [],
   "source": [
    "# Not set earlier because pip may require a restart.\n",
    "SESSN_START_T, = !date +%Y%m%dT%H%M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTX1BGNQN6VB"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lg9kMsARWAIu"
   },
   "outputs": [],
   "source": [
    "# Set a constant seed for every random number generator.\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True  # About 15% slower but...\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "db_RafAMN2mK"
   },
   "outputs": [],
   "source": [
    "# A special treatment for colab to decrease network traffic.\n",
    "fastprogress.NO_BAR = True\n",
    "master_bar, progress_bar = fastprogress.force_console_behavior()\n",
    "basic_train.master_bar, basic_train.progress_bar = master_bar, progress_bar\n",
    "basic_data.master_bar, basic_data.progress_bar = master_bar, progress_bar\n",
    "dataclass.master_bar, dataclass.progress_bar = master_bar, progress_bar\n",
    "text.master_bar, text.progress_bar = master_bar, progress_bar\n",
    "text.data.master_bar, text.data.progress_bar = master_bar, progress_bar\n",
    "core.master_bar, core.progress_bar = master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDMmtPemp8H3"
   },
   "outputs": [],
   "source": [
    "GD_DIR_S = '/content/gdrive/'\n",
    "drive.mount(GD_DIR_S, force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uDRg1_MUpXjy"
   },
   "outputs": [],
   "source": [
    "BASE_DIR_P = GD_DIR_S / Path('My Drive/imdb/')\n",
    "BASE_DIR_P.mkdir(parents=True, exist_ok=True)\n",
    "DATA_DIR_P = BASE_DIR_P / 'data/'\n",
    "DATA_DIR_P.mkdir(parents=True, exist_ok=True)\n",
    "MDLS_DIR_P = BASE_DIR_P / 'models/'\n",
    "MDLS_DIR_P.mkdir(parents=True, exist_ok=True)\n",
    "LOGS_DIR_P = BASE_DIR_P / 'logs/'\n",
    "LOGS_DIR_P.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FASTAI_DATA_DIR_P = Path('/root/.fastai/data/')\n",
    "FASTAI_DATA_DIR_P.mkdir(parents=True, exist_ok=True)\n",
    "Path('/content/data').symlink_to(FASTAI_DATA_DIR_P)\n",
    "FASTAI_MDLS_DIR_P = Path('/root/.torch/models/')\n",
    "FASTAI_MDLS_DIR_P.mkdir(parents=True, exist_ok=True)\n",
    "Path('/content/models').symlink_to(FASTAI_MDLS_DIR_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtgjNtwUnkTs"
   },
   "outputs": [],
   "source": [
    "!set -x; rm -rf /content/sample_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4puv1GrLOp5R"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2RKejF7YdPR"
   },
   "source": [
    "## Assign Shared Hyperparams & Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y18xZgbnXVMo"
   },
   "outputs": [],
   "source": [
    "bs = 64\n",
    "bptt = 80  # From the example, but fastai defaults to 70.\n",
    "moms = (0.8,0.7)\n",
    "wd = 0.1  # The example uses fastai default 1e-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P381SP4eYxv8"
   },
   "outputs": [],
   "source": [
    "# Set num_workers to main process since the training set will be shuffled.\n",
    "n_dbnch_wrkrs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ta3mx4aMZG_E"
   },
   "outputs": [],
   "source": [
    "FW_DBNCH_FILE_S = 'fw_dbnch.pkl'\n",
    "FW_DBNCH_P = DATA_DIR_P / FW_DBNCH_FILE_S\n",
    "FW_ENC_NAME = 'fw_enc'\n",
    "FW_MDL_NAME = 'imdb_fw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNPkxIB_ZPhC"
   },
   "outputs": [],
   "source": [
    "fw_log_file_p = BASE_DIR_P / f'logs/{SESSN_START_T}_history-fw.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wopKpHoLPRj5"
   },
   "source": [
    "## Process Data Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aUayc5jQ-ugt"
   },
   "outputs": [],
   "source": [
    "# Untar into colab disk so no latency to GDrive.\n",
    "colab_dir_p = untar_data(URLs.IMDB, dest=FASTAI_DATA_DIR_P)\n",
    "colab_dir_p.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0NkAvKG-ug3"
   },
   "outputs": [],
   "source": [
    "lm_dbnch = (TextList.from_folder(colab_dir_p)\n",
    "            #Inputs: all the text files in path\n",
    "            .filter_by_folder(include=['train', 'test', 'unsup'])\n",
    "            #We may have other temp folders that contain text files so we only keep what's in train and test\n",
    "            .split_by_rand_pct(\n",
    "                0.1,\n",
    "                seed=SEED  # Set the seed again since in theory one can call np.random before this.\n",
    "            )\n",
    "            #We randomly split and keep 10% (10,000 reviews) for validation\n",
    "            .label_for_lm()\n",
    "            #We want to do a language model so we label accordingly\n",
    "            .databunch(bs=bs, bptt=bptt, num_workers=n_dbnch_wrkrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YhsoGj4Z-ug5"
   },
   "outputs": [],
   "source": [
    "lm_dbnch.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zt0DL_dOjokO"
   },
   "source": [
    "## Use Persistent Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cm_heHy78zKl"
   },
   "outputs": [],
   "source": [
    "# Save and load the databunch using a non-voatile path (e.g.: GDrive).\n",
    "lm_dbnch.save(FW_DBNCH_P)\n",
    "fw_lm_dbnch = load_data(DATA_DIR_P, FW_DBNCH_FILE_S, bs=bs, bptt=bptt, num_workers=n_dbnch_wrkrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FX1Rpmq5-iL4"
   },
   "outputs": [],
   "source": [
    "# The batch should look the same if the above efforts keep the reproducibility.\n",
    "fw_lm_dbnch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXznsF3Vsc1-"
   },
   "outputs": [],
   "source": [
    "# Backward counterparts are not implemented yet.\n",
    "\n",
    "# bw_lm_dbnch = load_data(DATA_DIR_P, FW_DBNCH_FILE_S, bs=bs, bptt=bptt, num_workers=n_dbnch_wrkrs, backwards=True)\n",
    "# bw_lm_dbnch.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3uudRrTXGq3"
   },
   "source": [
    "## Fit LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJnkgQiJqCyZ"
   },
   "outputs": [],
   "source": [
    "def init_learner(dbnch, drop_mult):\n",
    "  learner = language_model_learner(dbnch, AWD_LSTM, drop_mult=drop_mult)\n",
    "  learner = learner.to_fp16(clip=0.1)  # 2x faster\n",
    "  return learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMflNyYdm-S7"
   },
   "outputs": [],
   "source": [
    "def fit_lm_1st_cycle(learner, lr, moms, wd, csv_logger):\n",
    "  learner.fit_one_cycle(1, lr, moms=moms, wd=wd, callbacks=[csv_logger])\n",
    "  learner.save('fit_head')\n",
    "  display(learner.path.ls())\n",
    "  return learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BngsYt2inEak"
   },
   "outputs": [],
   "source": [
    "def fit_lm_rest_cycles(learner, lr, moms, wd, csv_logger, n_cycles=10):\n",
    "  learner.unfreeze()\n",
    "  learner.fit_one_cycle(n_cycles, lr, moms=moms, wd=wd, callbacks=[csv_logger])\n",
    "  return learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B_qzqZBBnWM2"
   },
   "source": [
    "### Assign LM-specific Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aw3aDcB_nT20"
   },
   "outputs": [],
   "source": [
    "# Decrease the lr from the example's 2e-2 proportionally to the orig bs=256.\n",
    "orig_bs = 256\n",
    "lm_lr = bs / orig_bs * 2e-2\n",
    "\n",
    "# The example uses 1.0, probably because no pretrained models for it yet?\n",
    "drop_mult = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7zjxYNY_pNAp"
   },
   "source": [
    "### Fit Forward LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgCTJWeUqmhL"
   },
   "outputs": [],
   "source": [
    "fw_lm_learn = init_learner(fw_lm_dbnch, drop_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CJHXFu6XqUlT"
   },
   "outputs": [],
   "source": [
    "# Not sure why partial didn't work, so initialize the logger here.\n",
    "fw_lm_csv_logger = callbacks.CSVLogger(fw_lm_learn, fw_log_file_p, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9Du6uwe-ug-"
   },
   "outputs": [],
   "source": [
    "fw_lm_learn = fit_lm_1st_cycle(fw_lm_learn, lm_lr, moms, wd, fw_lm_csv_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 40
    },
    "colab_type": "code",
    "id": "0BoPb4vX-uhD",
    "outputId": "39ae2ad1-77fb-4108-8d03-3fef3ad0470b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  time    \n"
     ]
    }
   ],
   "source": [
    "fw_lm_learn = fit_lm_rest_cycles(fw_lm_learn, lm_lr/10, moms, wd, fw_lm_csv_logger, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvF0RhTu-uhH"
   },
   "outputs": [],
   "source": [
    "# Redundant to fw_lm_dbnch.save()?\n",
    "fw_lm_learn.save('tuned_fw_lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hfx6-4ce-uhK"
   },
   "outputs": [],
   "source": [
    "fw_lm_learn.save_encoder(FW_ENC_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YrumMXW2-uhN"
   },
   "outputs": [],
   "source": [
    "fw_lm_dbnch.save(FW_MDL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvbpbtNQVnP-"
   },
   "outputs": [],
   "source": [
    "fw_lm_learn.csv_logger.read_logged_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WjQGr4V-VmxC"
   },
   "outputs": [],
   "source": [
    "fw_lm_learn.path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8L_H4uC91mn"
   },
   "source": [
    "### Fit Forward Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KN8hrD2U-uhS"
   },
   "outputs": [],
   "source": [
    "fw_cf_dbnch = (TextList.from_folder(colab_dir_p, vocab=fw_lm_dbnch.vocab)\n",
    "               #grab all the text files in path\n",
    "               .split_by_folder(valid='test')\n",
    "               #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "               .label_from_folder(classes=['neg', 'pos'])\n",
    "               #label them all with their folders\n",
    "               .databunch(bs=bs, num_workers=n_dbnch_wrkrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87rleD4t-uhV"
   },
   "outputs": [],
   "source": [
    "fw_cf_learn = text_classifier_learner(fw_cf_dbnch, AWD_LSTM, drop_mult=0.5)\n",
    "#learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPbiuSMEIzvl"
   },
   "outputs": [],
   "source": [
    "# Not sure why this was 2e-2 for the classifier; the example uses 1e-1.\n",
    "cf_lr = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2NCe-QlT-uhX"
   },
   "outputs": [],
   "source": [
    "fw_cf_learn.fit_one_cycle(1, cf_lr, moms=moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yk0Trw3K-uha"
   },
   "outputs": [],
   "source": [
    "fw_cf_learn.freeze_to(-2)\n",
    "cf_lr /= 2\n",
    "fw_cf_learn.fit_one_cycle(1, slice(cf_lr/(2.6**4),cf_lr), moms=moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kftGl7Nm-uhd"
   },
   "outputs": [],
   "source": [
    "fw_cf_learn.freeze_to(-3)\n",
    "cf_lr /= 2\n",
    "fw_cf_learn.fit_one_cycle(1, slice(cf_lr/(2.6**4),cf_lr), moms=moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5SD5wkM-uhf"
   },
   "outputs": [],
   "source": [
    "fw_cf_learn.unfreeze()\n",
    "cf_lr /= 5\n",
    "fw_cf_learn.fit_one_cycle(2, slice(cf_lr/(2.6**4),cf_lr), moms=moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tgl3cIVv-uhj"
   },
   "outputs": [],
   "source": [
    "fw_cf_learn.save('fwd_clas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utocq7wcC-lo",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Incomplete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKi2fjvo-uho",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Not sure what was the purpose of these.\n",
    "\n",
    "data_clas = TextDataBunch.load(path/'tmp_clas/','.')\n",
    "\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "#np.load = np_load_old\n",
    "\n",
    "learn.load(\"../../models/clas\");"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "imdb.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
