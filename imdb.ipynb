{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tianjianjiang/nlp_data_aug/blob/%231-control_random_factors/imdb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9LbB0krq6z2",
        "colab_type": "text"
      },
      "source": [
        "# Prepare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMnqAd1HJ1Br",
        "colab_type": "text"
      },
      "source": [
        "An example as baseline: [ULMFit](https://nbviewer.jupyter.org/github/fastai/fastai/blob/master/examples/ULMFit.ipynb) tutorial.\n",
        "\n",
        "> Fine-tuning a forward and backward langauge model to get to 95.4% accuracy on the IMDB movie reviews dataset. This tutorial is done with fastai v1.0.53.\n",
        "\n",
        "> The example was run on a Titan RTX (24 GB of RAM) so you will probably need to adjust the batch size accordinly. If you divide it by 2, don't forget to divide the learning rate by 2 as well in the following cells. You can also reduce a little bit the bptt to gain a bit of memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF718toQqs83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensure GPU spec; T4 is for colab and one can change it for another env.\n",
        "gpu_list = !nvidia-smi -L\n",
        "if gpu_list[0].startswith('NVIDIA-SMI has failed'):\n",
        "  print('Runtime type should be GPU.')\n",
        "elif not gpu_list[0].startswith('GPU 0: Tesla T4'):\n",
        "  display(gpu_list)\n",
        "  print('Please reset all runtimes. We need a Tesla T4 to reproduce the experiments!')\n",
        "else:\n",
        "  display(gpu_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OcNDqMgrCca",
        "colab_type": "text"
      },
      "source": [
        "## Dependency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrjoIzboW09N",
        "colab_type": "text"
      },
      "source": [
        "### Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rwtTuykrEWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensure no surprises from conflict packages.\n",
        "!pip check"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bymTjo9wrz5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U fastai==1.0.55 jupyter-console==5.2.0 coveralls coverage datascience albumentations\n",
        "!pip check"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z1_46NArGi_",
        "colab_type": "text"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMm8qgQqD2eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from google.colab import drive\n",
        "\n",
        "from fastai import basic_train, basic_data, core\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastprogress import fastprogress"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTVchfsRnLgI",
        "colab_type": "text"
      },
      "source": [
        "### Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnxWkqafNxvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Not set earlier because pip may require a restart.\n",
        "SESSN_START_T, = !date +%Y%m%dT%H%M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTX1BGNQN6VB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db_RafAMN2mK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A special treatment for colab to decrease network traffic.\n",
        "fastprogress.NO_BAR = True\n",
        "master_bar, progress_bar = fastprogress.force_console_behavior()\n",
        "basic_train.master_bar, basic_train.progress_bar = master_bar, progress_bar\n",
        "basic_data.master_bar, basic_data.progress_bar = master_bar, progress_bar\n",
        "dataclass.master_bar, dataclass.progress_bar = master_bar, progress_bar\n",
        "text.master_bar, text.progress_bar = master_bar, progress_bar\n",
        "text.data.master_bar, text.data.progress_bar = master_bar, progress_bar\n",
        "core.master_bar, core.progress_bar = master_bar, progress_bar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDMmtPemp8H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GD_DIR_S = '/content/gdrive/'\n",
        "drive.mount(GD_DIR_S, force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDRg1_MUpXjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_DIR_P = GD_DIR_S / Path('My Drive/imdb/')\n",
        "BASE_DIR_P.mkdir(parents=True, exist_ok=True)\n",
        "DATA_DIR_P = BASE_DIR_P / 'data/'\n",
        "DATA_DIR_P.mkdir(parents=True, exist_ok=True)\n",
        "LOGS_DIR_P = BASE_DIR_P / 'logs/'\n",
        "LOGS_DIR_P.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "FASTAI_DATA_DIR_P = Path('/root/.fastai/data/')\n",
        "FASTAI_DATA_DIR_P.mkdir(parents=True, exist_ok=True)\n",
        "Path('/content/data').symlink_to(FASTAI_DATA_DIR_P)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtgjNtwUnkTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!set -x; rm -rf /content/sample_data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2RKejF7YdPR",
        "colab_type": "text"
      },
      "source": [
        "# Assign"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjmk-4Y_OWc-",
        "colab_type": "text"
      },
      "source": [
        "## Shared Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y18xZgbnXVMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm_bs = 64\n",
        "cf_bs = round(lm_bs / 2)\n",
        "print(f'Our lm_bs: {lm_bs}; cf_bs: {cf_bs}')\n",
        "bptt = 80  # From the example, but fastai defaults to 70.\n",
        "moms = (0.8, 0.7)\n",
        "wd = 0.1  # From the example, except forward classifier uses fastai default 1e-2."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_qzqZBBnWM2",
        "colab_type": "text"
      },
      "source": [
        "## LM-specific Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw3aDcB_nT20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decrease the lr from the example's 2e-2 proportionally to the orig lm bs 256.\n",
        "ORIG_LM_BS = 256\n",
        "ORIG_LM_LR = 2e-2\n",
        "lm_lr = lm_bs / ORIG_LM_BS * ORIG_LM_LR\n",
        "print(f'In proportion to our lm_bs, our lm_lr : {lm_lr}')\n",
        "\n",
        "lm_drop_mult = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwAPR52UFvUW",
        "colab_type": "text"
      },
      "source": [
        "## CF-specific Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR72_ylXFu7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ORIG_CF_BS = round(ORIG_LM_BS / 2)\n",
        "ORIG_CF_LR = 1e-1\n",
        "cf_lr = cf_bs / ORIG_CF_BS * ORIG_CF_LR\n",
        "print(f'In proportion to our cf_bs, our cf_lr: {cf_lr}')\n",
        "\n",
        "cf_drop_mult = lm_drop_mult / 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNg8nWEyOj1F",
        "colab_type": "text"
      },
      "source": [
        "## Args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P381SP4eYxv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set num_workers to main process since the training set will be shuffled.\n",
        "n_dbnch_wrkrs = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta3mx4aMZG_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FW_LM_DBNCH_FILE_S = f'fw_lm_dbnch-b{lm_bs}.pkl'\n",
        "BW_LM_DBNCH_FILE_S = f'bw_lm_dbnch-b{lm_bs}.pkl'\n",
        "\n",
        "FW_ENC_NAME = f'fw_enc-b{lm_bs}'\n",
        "BW_ENC_NAME = f'bw_enc-b{lm_bs}'\n",
        "\n",
        "FW_CF_DBNCH_FILE_S = f'fw_cf_dbnch-b{cf_bs}.pkl'\n",
        "BW_CF_DBNCH_FILE_S = f'bw_cf_dbnch-b{cf_bs}.pkl'\n",
        "\n",
        "FW_CF_NAME = f'fw_cf-b{cf_bs}'\n",
        "BW_CF_NAME = f'bw_cf-b{cf_bs}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEfPdqf-I-bZ",
        "colab_type": "text"
      },
      "source": [
        "# Define"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAhmWnGMZh7q",
        "colab_type": "text"
      },
      "source": [
        "## Random State Fixer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6ETnToMbEuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set a constant seed for every random number generator.\n",
        "SEED = 42\n",
        "\n",
        "def reset_all_nondeterministic_states(seed=SEED):\n",
        "  random.seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  torch.manual_seed(SEED)\n",
        "  if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
        "  torch.backends.cudnn.deterministic = True  # About 15% slower but...\n",
        "  torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJwkXFIyJlkB",
        "colab_type": "text"
      },
      "source": [
        "## LM-specific Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjm3439wUJUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_lm_databunch(data_dir_p, n_workers, bs, bptt):\n",
        "  reset_all_nondeterministic_states()\n",
        "  return (TextList.from_folder(data_dir_p)\n",
        "          #Inputs: all the text files in path\n",
        "          .filter_by_folder(include=['train', 'test', 'unsup'])\n",
        "          #We may have other temp folders that contain text files so we only keep what's in train and test\n",
        "          .split_by_rand_pct(\n",
        "              0.1,\n",
        "              seed=SEED  # Set the seed again since in theory one can call np.random before this.\n",
        "          )\n",
        "          #We randomly split and keep 10% (10,000 reviews) for validation\n",
        "          .label_for_lm()\n",
        "          #We want to do a language model so we label accordingly\n",
        "          .databunch(bs=bs, bptt=bptt, num_workers=n_workers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJnkgQiJqCyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_lm_learner_with_ulmfit(dbnch, drop_mult, base_path=BASE_DIR_P):\n",
        "  lm_learn = language_model_learner(dbnch, AWD_LSTM, drop_mult=drop_mult, path=base_path)\n",
        "  lm_learn = lm_learn.to_fp16(clip=0.1)  # 2x faster\n",
        "  return lm_learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMflNyYdm-S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_lm_cycles(learner, lr, moms, wd, clbks=[], n_cycles=1):\n",
        "  print(f'init lm lr: {lr}')\n",
        "  reset_all_nondeterministic_states()\n",
        "  learner.fit_one_cycle(n_cycles, lr, moms=moms, wd=wd, callbacks=clbks)\n",
        "  return learner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BngsYt2inEak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tune_lm_cycles(learner, lr, moms, wd, clbks=[], n_cycles=10):\n",
        "  print(f'tune lm lr: {lr}')\n",
        "  reset_all_nondeterministic_states()\n",
        "  learner.unfreeze()\n",
        "  learner.fit_one_cycle(n_cycles, lr, moms=moms, wd=wd, callbacks=clbks)\n",
        "  return learner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7ygpuHbJo0t",
        "colab_type": "text"
      },
      "source": [
        "## CF-specific Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPkphOtiXTHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_cf_databunch(data_dir_p, n_workers, bs, vocab):\n",
        "  return (TextList.from_folder(data_dir_p, vocab=vocab)\n",
        "          #grab all the text files in path\n",
        "          .split_by_folder(valid='test')\n",
        "          #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
        "          .label_from_folder(classes=['neg', 'pos'])\n",
        "          #label them all with their folders\n",
        "          .databunch(bs=bs, num_workers=n_workers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_754QK6Ju61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_cf_learner_with_encoder(dbnch, drop_mult, enc_name, base_path=BASE_DIR_P):\n",
        "  cf_learn = text_classifier_learner(dbnch, AWD_LSTM, drop_mult=drop_mult, path=base_path, pretrained=False)\n",
        "  cf_learn.load_encoder(enc_name)\n",
        "  return cf_learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chGUzivkKYy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_cf_cycles(learner, lr, moms, wd, clbks, n_cycles=1):\n",
        "  print(f'init cf lr: {lr}')\n",
        "  reset_all_nondeterministic_states()\n",
        "  learner.fit_one_cycle(n_cycles, lr, moms=moms, wd=wd, callbacks=clbks)\n",
        "  return learner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx3iwNXOLJQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tune_cf_cycles(\n",
        "    learner,\n",
        "    lr,\n",
        "    moms,\n",
        "    wd,\n",
        "    clbks_tuple,\n",
        "    n_cycles_tuple=(1,1,2),\n",
        "    freeze_steps=(-2,-3,None),\n",
        "    lr_decays=(2,2,5)\n",
        "):\n",
        "  reset_all_nondeterministic_states()\n",
        "  for n_cycles, freeze_step, lr_decay, clbks in zip(\n",
        "      n_cycles_tuple, freeze_steps, lr_decays, clbks_tuple):\n",
        "    if freeze_step is not None:\n",
        "      learner.freeze_to(freeze_step)\n",
        "    else:\n",
        "      learner.unfreeze()\n",
        "    lr /= lr_decay\n",
        "    print(f'tune cf lr: {lr}')\n",
        "    learner.fit_one_cycle(n_cycles, slice(lr/(2.6**4),lr), moms=moms, wd=wd, callbacks=clbks)\n",
        "  return learner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4puv1GrLOp5R",
        "colab_type": "text"
      },
      "source": [
        "# Fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3uudRrTXGq3",
        "colab_type": "text"
      },
      "source": [
        "## Forward LM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wopKpHoLPRj5",
        "colab_type": "text"
      },
      "source": [
        "#### Process Data Once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUayc5jQ-ugt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Untar into colab disk so no latency to GDrive.\n",
        "colab_dir_p = untar_data(URLs.IMDB, dest=FASTAI_DATA_DIR_P)\n",
        "colab_dir_p.ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0NkAvKG-ug3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm_dbnch = build_lm_databunch(colab_dir_p, n_dbnch_wrkrs, lm_bs, bptt)\n",
        "# lm_dbnch.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt0DL_dOjokO",
        "colab_type": "text"
      },
      "source": [
        "#### Use Persistent Path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm_heHy78zKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save and load the databunch using a non-voatile path (e.g.: GDrive).\n",
        "lm_dbnch.save(DATA_DIR_P / FW_LM_DBNCH_FILE_S)\n",
        "fw_lm_dbnch = load_data(DATA_DIR_P, FW_LM_DBNCH_FILE_S, bs=lm_bs, bptt=bptt, num_workers=n_dbnch_wrkrs)\n",
        "# fw_lm_dbnch.path.ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX1Rpmq5-iL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The batch should look the same if the above efforts keep the reproducibility.\n",
        "# fw_lm_dbnch.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKqmxK2NHvbY",
        "colab_type": "text"
      },
      "source": [
        "#### Init-fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgCTJWeUqmhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fw_lm_learn = init_lm_learner_with_ulmfit(fw_lm_dbnch, lm_drop_mult)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJHXFu6XqUlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Not sure why partial didn't work, so initialize the logger here.\n",
        "init_fw_lm_log_p = LOGS_DIR_P / f'{SESSN_START_T}_history-init_fw_lm-b{lm_bs}'  # w/o .csv\n",
        "init_fw_lm_clbks = [callbacks.CSVLogger(fw_lm_learn, init_fw_lm_log_p, append=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE6Zy_bkYpyo",
        "colab_type": "code",
        "outputId": "c3116537-7373-4848-fafc-a6b6a8fabde1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "fw_lm_learn = init_lm_cycles(fw_lm_learn, lm_lr, moms, wd, init_fw_lm_clbks)\n",
        "# fw_lm_learn.csv_logger.read_logged_file()\n",
        "fw_lm_learn.save(f'init_fw_lm-b{lm_bs}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init lm lr: 0.005\n",
            "epoch     train_loss  valid_loss  accuracy  time    \n",
            "0         4.380906    4.081290    0.290308  17:22     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZi-YvMBhEWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (fw_lm_learn.path/fw_lm_learn.model_dir).ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhGjAxk1IHCQ",
        "colab_type": "text"
      },
      "source": [
        "#### Fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpN7nfwzYvFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tune_fw_lm_log_p = LOGS_DIR_P / f'{SESSN_START_T}_history-tune_fw_lm-b{lm_bs}'\n",
        "tune_fw_lm_clbks = [callbacks.CSVLogger(fw_lm_learn, tune_fw_lm_log_p, append=True)]\n",
        "fw_lm_learn = tune_lm_cycles(fw_lm_learn, lm_lr/10, moms, wd, tune_fw_lm_clbks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0BoPb4vX-uhD",
        "colab_type": "code",
        "outputId": "eca9e393-5906-48ff-e1e6-df04778c7a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tune lm lr: 0.0005\n",
            "epoch     train_loss  valid_loss  accuracy  time    \n",
            "0         4.156863    3.955999    0.304184  20:33     \n",
            "1         4.055799    3.887233    0.313336  20:34     \n",
            "2         4.009748    3.843621    0.318697  20:32     \n",
            "3         3.974771    3.816171    0.322405  20:33     \n",
            "4         3.945872    3.796026    0.324830  20:31     \n",
            "5         3.914127    3.773188    0.327346  20:34     \n",
            "6         3.889194    3.756511    0.329368  20:34     \n",
            "7         3.863370    3.741999    0.331158  20:33     \n",
            "8         3.855726    3.733190    0.332307  20:34     \n",
            "9         3.844754    3.730709    0.332586  20:35     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvF0RhTu-uhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fw_lm_learn.save(f'tuned_fw_lm-b{lm_bs}')\n",
        "fw_lm_learn.save_encoder(FW_ENC_NAME)\n",
        "# (fw_lm_learn.path/fw_learn_lm.model_dir).ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8L_H4uC91mn",
        "colab_type": "text"
      },
      "source": [
        "## Forward CF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN8hrD2U-uhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fw_lm_dbnch = load_data(DATA_DIR_P, FW_LM_DBNCH_FILE_S, bs=lm_bs, bptt=bptt, num_workers=n_dbnch_wrkrs)\n",
        "cf_dbnch = build_cf_databunch(colab_dir_p, n_dbnch_wrkrs, cf_bs, fw_lm_dbnch.vocab)\n",
        "cf_dbnch.save(DATA_DIR_P / FW_CF_DBNCH_FILE_S)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj7AbXlyGodP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fw_cf_dbnch = load_data(DATA_DIR_P, FW_CF_DBNCH_FILE_S, bs=cf_bs, num_workers=n_dbnch_wrkrs)\n",
        "# fw_cf_dbnch.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87rleD4t-uhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fw_cf_learn = init_cf_learner_with_encoder(fw_cf_dbnch, cf_drop_mult, FW_ENC_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Hj2JpsY4Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_fw_cf_log_p = LOGS_DIR_P / f'{SESSN_START_T}_history-init_fw_cf-b{cf_bs}'\n",
        "init_fw_cf_clbks = [callbacks.CSVLogger(fw_cf_learn, init_fw_cf_log_p, append=True)]\n",
        "fw_cf_learn = init_cf_cycles(fw_cf_learn, cf_lr, moms, wd, init_fw_cf_clbks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7BTyW5ZQa1j",
        "colab_type": "code",
        "outputId": "a2828676-c848-47f2-ed70-b4cc057304c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init cf lr: 0.037500000000000006\n",
            "epoch     train_loss  valid_loss  accuracy  time    \n",
            "0         0.224170    0.185326    0.930120  05:03     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJrVnIh8Y7AY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tune_fw_cf_clbks_tuple = (\n",
        "    [callbacks.CSVLogger(\n",
        "        fw_cf_learn,\n",
        "        LOGS_DIR_P / f'{SESSN_START_T}_history-tune_fw_cf-b{cf_bs}-p{period}',\n",
        "        append=True)]\n",
        "    for period in range(1,4)\n",
        ")\n",
        "fw_cf_learn = tune_cf_cycles(fw_cf_learn, cf_lr, moms, wd, tune_fw_cf_clbks_tuple)\n",
        "fw_cf_learn.save(FW_CF_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4UcCxmaQtlL",
        "colab_type": "code",
        "outputId": "43427664-71aa-4a5e-bdbf-d9eb4235bc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tune cf lr: 0.018750000000000003\n",
            "epoch     train_loss  valid_loss  accuracy  time    \n",
            "0         0.208068    0.156441    0.941680  06:26     \n",
            "tune cf lr: 0.009375000000000001\n",
            "epoch     train_loss  valid_loss  accuracy  time    \n",
            "0         0.190641    0.147478    0.945200  08:04     \n",
            "tune cf lr: 0.0018750000000000004\n",
            "epoch     train_loss  valid_loss  accuracy  time    \n",
            "0         0.153830    0.144531    0.946640  10:40     \n",
            "1         0.091982    0.145425    0.947800  09:58     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWH4vjK2_qrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (fw_cf_learn.path/fw_cf_learn.model_dir).ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHXVFNpK-ioI",
        "colab_type": "text"
      },
      "source": [
        "## Backward LM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhP0h1Xd-mbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bw_lm_dbnch = load_data(DATA_DIR_P, FW_LM_DBNCH_FILE_S, bs=lm_bs, bptt=bptt, num_workers=n_dbnch_wrkrs, backwards=True)\n",
        "# bw_lm_dbnch.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raVmaLmN_V1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bw_lm_learn = init_lm_learner_with_ulmfit(bw_lm_dbnch, lm_drop_mult)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huSk-BF1VLVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_bw_lm_log_p = LOGS_DIR_P / f'{SESSN_START_T}_history-init_bw_lm'\n",
        "init_bw_lm_clbks = [callbacks.CSVLogger(bw_lm_learn, init_bw_lm_log_p, append=True)]\n",
        "bw_lm_learn = init_lm_cycles(bw_lm_learn, lm_lr, moms, wd, init_bw_lm_clbks)\n",
        "bw_lm_learn.save('init_bw_lm')\n",
        "# (bw_lm_learn.path/bw_lm_learn.model_dir).ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NUSb7-b_8iF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tune_bw_lm_log_p = LOGS_DIR_P / f'{SESSN_START_T}_history-tune_bw_lm'\n",
        "tune_bw_lm_clbks = [callbacks.CSVLogger(bw_lm_learn, tune_bw_lm_log_p, append=True)]\n",
        "bw_lm_learn = tune_lm_cycles(bw_lm_learn, lm_lr/10, moms, wd, tune_bw_lm_clbks)\n",
        "bw_lm_learn.save('tuned_bw_lm')\n",
        "bw_lm_learn.save_encoder(BW_ENC_NAME)\n",
        "# (bw_lm_learn.path/bw_lm_learn.model_dir).ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-hoCyr3-qBS",
        "colab_type": "text"
      },
      "source": [
        "## Backward CF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrP_-kGk-sUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bw_cf_dbnch = load_data(DATA_DIR_P, FW_CF_DBNCH_FILE_S, bs=cf_bs, num_workers=n_dbnch_wrkrs, backwards=True)\n",
        "# bw_cf_dbnch.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uskEorwDQjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bw_cf_learn = init_cf_learner_with_encoder(fw_cf_dbnch, cf_drop_mult, FW_ENC_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97wzmm0BgLIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_bw_cf_log_p = LOGS_DIR_P / f'{SESSN_START_T}_history-init_bw_cf'\n",
        "init_bw_cf_clbks = [callbacks.CSVLogger(bw_cf_learn, init_bw_cf_log_p, append=True)]\n",
        "bw_cf_learn = init_cf_cycles(bw_cf_learn, cf_lr, moms, wd, init_bw_cf_clbks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPLl7lNKIvzi",
        "colab_type": "code",
        "outputId": "bd4f96bb-73c6-4eb0-f0da-21e45d2396fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init cf lr: 0.037500000000000006\n",
            "epoch     train_loss  valid_loss  accuracy  time    \n",
            "0         0.237566    0.184433    0.929280  05:15     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGO-UK8qgNva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tune_bw_cf_clbks_tuple = (\n",
        "    [callbacks.CSVLogger(\n",
        "        bw_cf_learn,\n",
        "        LOGS_DIR_P / f'{SESSN_START_T}_history-tune_bw_cf-p{period}',\n",
        "        append=True)]\n",
        "    for period in range(1,4)\n",
        ")\n",
        "bw_cf_learn = tune_cf_cycles(bw_cf_learn, cf_lr, moms, wd, tune_bw_cf_clbks_tuple)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ycpADVIPLNf",
        "colab_type": "code",
        "outputId": "61b63b87-a996-484d-fbca-505ab6397a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tune cf lr: 0.018750000000000003\n",
            "epoch     train_loss  valid_loss  accuracy  time    \n",
            "0         0.200242    0.155295    0.942120  06:33     \n",
            "tune cf lr: 0.009375000000000001\n",
            "epoch     train_loss  valid_loss  accuracy  time    \n",
            "0         0.193940    0.151276    0.944640  07:51     \n",
            "tune cf lr: 0.0018750000000000004\n",
            "epoch     train_loss  valid_loss  accuracy  time    \n",
            "0         0.165703    0.142958    0.948120  11:49     \n",
            "1         0.095749    0.145562    0.949080  11:04     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6EkkUVvPaeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bw_cf_learn.save(BW_CF_NAME)\n",
        "# (bw_cf_learn.path/bw_cf_learn.model_dir).ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jXi1C4y5BT",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG7qKU4Xy4kI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_fw, lbl_fw = fw_cf_learn.get_preds(ordered=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eqG0vYj1tCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_bw, lbl_bw = bw_cf_learn.get_preds(ordered=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeQ8zEtC1vIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_pred = (pred_fw + pred_bw) / 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMKz-Tp41w_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy(avg_pred, lbl_fw)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}